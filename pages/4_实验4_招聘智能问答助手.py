

import streamlit as st
st.set_page_config(page_title="æ‹›è˜æ™ºèƒ½åŠ©æ‰‹")

import pandas as pd
import json
import os
from utils.glm import init_glm_ai, ask_glm
from utils.functions import get_skill_distribution, get_recommend_jobs, get_skill_requirements

MEMORY_FILE = "chat_history.json"

def save_message(message):
    history = load_history()
    history.append(message)
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def load_history():
    if not os.path.exists(MEMORY_FILE):
        return []
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def clear_history():
    if os.path.exists(MEMORY_FILE):
        os.remove(MEMORY_FILE)

@st.cache_data
def load_dataset():
    return pd.read_csv("data/æ‹›è˜æ•°æ®é›†(å«æŠ€èƒ½åˆ—è¡¨ï¼‰.csv")

dataset = load_dataset()

# æ³¨å†Œå‡½æ•°
function_list = {
    "get_skill_distribution": get_skill_distribution,
    "get_recommend_jobs": get_recommend_jobs,
    "get_skill_requirements": get_skill_requirements
}

# æ³¨å†Œ tools
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_skill_distribution",
            "description": "è·å–æŠ€èƒ½å¯¹åº”çš„çƒ­é—¨å²—ä½",
            "parameters": {
                "type": "object",
                "properties": {
                    "skill": {"type": "string"}
                }
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_recommend_jobs",
            "description": "æ ¹æ®å…³é”®è¯æ¨èç›¸å…³å²—ä½ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "keyword": {"type": "string"}
                },
                "required": ["keyword"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_skill_requirements",
            "description": "åˆ†æå²—ä½å¸¸è§æŠ€èƒ½",
            "parameters": {
                "type": "object",
                "properties": {
                    "keyword": {"type": "string"}
                },
                "required": ["keyword"]
            }
        }
    }
]

# ğŸ›ï¸ ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("æ‹›è˜æ™ºèƒ½åŠ©æ‰‹è®¾ç½®")
    key = st.text_input("è¯·è¾“å…¥ API Token:", type="password")
    if key:
        st.success("âœ… API Token å·²é…ç½®")
    else:
        st.warning("âš ï¸ è¯·å…ˆè¾“å…¥ API Token")

    model = st.selectbox("é€‰æ‹©æ¨¡å‹", ["glm", "glm-4"])
    temperature = st.slider("temperature", 0.0, 1.5, 0.7)
    chart_type = st.selectbox("é€‰æ‹©å¯è§†åŒ–å›¾åƒç±»å‹", ["æ¡å½¢å›¾", "é¥¼å›¾", "è¡¨æ ¼"])
    st.session_state["chart_type"] = chart_type

    if st.button("æ¸…ç©ºèŠå¤©è®°å½•"):
        clear_history()
        st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯æ‹›è˜æ™ºèƒ½åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"}]

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = load_history()
    if not st.session_state.messages:
        st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯æ‹›è˜æ™ºèƒ½åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"}]

# å±•ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg.get("image"):
            st.image(msg["image"], use_container_width=True)
        if msg.get("table"):
            st.dataframe(pd.DataFrame(msg["table"]))

# ä¸»å¯¹è¯é€»è¾‘
if key and (prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")):
    api_key = init_glm_ai(key)

    user_msg = {"role": "user", "content": prompt}
    st.session_state.messages.append(user_msg)
    save_message(user_msg)

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("åˆ†æä¸­..."):

            skill_keywords = ["C++", "Java", "Python", "åµŒå…¥å¼", "ç®—æ³•", "Go", "æµ‹è¯•", "å‰ç«¯", "åç«¯"]
            matched_skill = next((kw for kw in skill_keywords if kw.lower() in prompt.lower()), None)

            # è‡ªåŠ¨åŠŸèƒ½è§¦å‘
            if "å¯ä»¥ä»äº‹ä»€ä¹ˆå²—ä½" in prompt and matched_skill:
                result = get_skill_distribution(dataset, skill=matched_skill, chart_type=st.session_state["chart_type"])

            elif "éœ€è¦ä»€ä¹ˆæŠ€èƒ½" in prompt and matched_skill:
                result = get_skill_requirements(dataset, keyword=matched_skill)

            elif "æ¨è" in prompt and matched_skill:
                result = get_recommend_jobs(dataset, keyword=matched_skill)

            else:
                result = ask_glm(
                    api_key,
                    tools=tools,
                    temperature=temperature,
                    content=prompt,
                    function_list=function_list,
                    dataset=dataset,
                    chart_type=st.session_state.get("chart_type", "é¥¼å›¾")
                )

            # æ¸²æŸ“è¾“å‡º
            if isinstance(result, dict) and "text" in result:
                st.markdown(result["text"])
                if result.get("plot"):
                    st.image(result["plot"], use_container_width=True)
                if isinstance(result.get("table"), pd.DataFrame):
                    st.dataframe(result["table"])

                assistant_msg = {
                    "role": "assistant",
                    "content": result["text"],
                    "image": result.get("plot"),
                    "table": result.get("table").to_dict() if isinstance(result.get("table"), pd.DataFrame) else None
                }
                st.session_state.messages.append(assistant_msg)
                save_message(assistant_msg)

            else:
                st.markdown(result)
                st.session_state.messages.append({"role": "assistant", "content": result})
                save_message({"role": "assistant", "content": result})
